# 教务数据智能决策平台方案设计（人工智能应用赛版）

## 1. 项目定位（比赛视角）

### 1.1 项目名称
教务数据智能决策平台（LangGraph + FastAPI + Vue 3）

### 1.2 核心定位
本项目是“人工智能应用”项目，而非“通用信息化系统”项目。  
核心价值是：把教务场景中依赖人工 SQL 和经验分析的流程，转化为可控、可审计、可落地的 AI 决策支持能力。

### 1.3 参赛主张（一句话）
构建“自然语言提问 -> 可验证 SQL -> 结构化结论”的闭环 AI 应用链路，解决高校教务管理中“会问不会查、会查不及时、能查难复用”的痛点。

---

## 2. 业务痛点与AI切入点

### 2.1 业务痛点
1. 教务分析依赖技术人员写 SQL，响应周期长。
2. 管理人员提出问题后，往往需多轮沟通才能形成可执行查询。
3. 传统问答式 AI 容易“说得像对的”，但缺少可验证依据。
4. 多系统、多口径导致指标理解不一致，分析结果复用难。

### 2.2 AI切入点
1. 用意图识别区分闲聊与业务查询，减少误调用。
2. 将自然语言解析为结构化任务（实体、指标、维度、过滤、时间范围）。
3. 基于结构化任务生成 SQL，并强制执行 SQL 校验与错误回退。
4. 通过失败救场机制（hidden_context）提升复杂问题成功率。

---

## 3. 总体方案与技术架构

### 3.1 架构总览
1. 前端：Vue 3 + TypeScript + Pinia（驾驶舱 + 聊天交互）。
2. 后端：FastAPI + SQLAlchemy（业务接口与 AI 工作流承载）。
3. 数据层：MySQL（教务业务数据、日志数据）。
4. AI 层：OpenAI 兼容模型接口 + LangGraph 工作流编排。
5. 运维层：Docker Compose + Nginx（含 SSE 反向代理配置）。

### 3.2 AI工作流（核心）
当前系统采用单图多节点工作流（非多 Agent）：
1. `intent_recognition`
2. `task_parse`
3. `sql_generation`
4. `sql_validate`
5. `hidden_context`
6. `result_return`

工作流状态由 `UnifiedChatGraphState` 统一维护，入口为 `execute_chat_workflow`。

---

## 4. 人工智能关键技术设计

### 4.1 技术路线
1. 任务分解式推理：将复杂问题拆成“识别-解析-生成-验证-纠错-返回”。
2. 结构化约束输出：关键节点输出 JSON 结构，避免自由文本失控。
3. 可执行验证闭环：生成 SQL 后必须经过语法/执行结果校验。
4. 失败恢复机制：对 unknown column/table、空结果、指标为零等异常进行重试纠偏。

### 4.2 节点级AI能力
1. 意图识别节点：识别 `chat` 与 `business_query`，并计算置信度阈值。
2. 任务解析节点：抽取实体、维度、指标、过滤条件、操作类型（detail/aggregate/ranking/trend）。
3. SQL生成节点：根据 schema 与解析结果生成可执行 SQL（可配置独立模型）。
4. SQL校验节点：执行有效性检查，识别空结果/零指标/执行错误。
5. Hidden Context 节点：基于报错与候选字段进行上下文修复并回跳重试。
6. 结果返回节点：统一输出 `final_status`、`reason_code`、`summary`、`download_url`。

### 4.3 关键工程机制（体现“应用”）
1. 流式可视化：SSE 输出 `workflow_start/step_start/step_end/workflow_end`，过程可观测。
2. 节点日志：`workflow_log` 持久化节点输入输出与错误信息，支持复盘优化。
3. 会话沉淀：`chat_history` 落库，支持连续对话与历史追踪。
4. 权限安全：JWT 鉴权 + 下载权限校验，满足实际管理场景要求。

---

## 5. 创新点（答辩重点）

1. 从“直接回答”升级为“可验证执行”
传统大模型问答输出结论，本项目输出可执行 SQL 与结构化结果，可信度更高。

2. 从“单次生成”升级为“错误自修复”
通过 `hidden_context` 在失败后自动补充上下文并重试，解决真实数据场景下的长尾错误。

3. 从“黑盒交互”升级为“全链路可观测”
前端可展示每个 AI 节点执行状态，后端日志可审计，便于工程治理与比赛展示。

4. 从“模型中心”升级为“业务价值中心”
强调教务治理效率提升，而非追求大模型参数规模。

---

## 6. 主要功能与应用场景

### 6.1 功能清单
1. 管理员认证与会话管理。
2. 教务主数据管理（学生、教师、课程等）。
3. CSV/XLSX 数据导入与错误反馈。
4. 驾驶舱概览与风险榜单导出。
5. 智能问答（同步/流式）与查询结果导出。

### 6.2 典型应用场景
1. 学业风险识别：按学期/学院/专业筛选风险名单并导出。
2. 管理问询即时响应：管理人员用自然语言提问得到结构化结果。
3. 指标追踪：趋势、排名、聚合分析快速生成。

---

## 7. 效果评估设计（比赛必讲）

### 7.1 评估维度
1. 可用性：业务问题成功返回比例。
2. 准确性：AI 解析结果与人工标注一致性。
3. 稳定性：流式交互完成率、失败回退成功率。
4. 效率：平均响应时长、人工 SQL 介入次数下降比例。

### 7.2 建议量化指标（按实测填写）
1. 业务问题闭环成功率：`__%`
2. SQL 一次通过率：`__%`
3. Hidden Context 救场成功率：`__%`
4. 平均响应时长：`__s`
5. 管理人员人工 SQL 依赖下降：`__%`

说明：以上数据可由 `workflow_log`、`chat_history` 与接口日志统计得到。

---

## 8. 落地成熟度与推广价值

### 8.1 成熟度
1. 项目已完成并上线运行。
2. 具备完整前后端、数据库、部署与运维配置。
3. 具备鉴权、安全、日志、导出等生产必备能力。

### 8.2 可推广性
1. 技术栈通用，可迁移至其他高校管理场景。
2. 工作流节点可扩展（可新增规则校验/知识检索/策略路由）。
3. 通过替换数据字典与提示词，可适配不同院校口径。

---

## 9. 风险与治理

1. 模型幻觉风险  
措施：结构化输出约束 + SQL 校验 + 错误回退。

2. 数据口径不一致风险  
措施：字段字典统一、指标定义固化、导入校验前置。

3. 高并发下响应抖动  
措施：SSE 超时与缓冲优化、后端连接池/并发参数调优、热点查询模板化。

---

## 10. 竞赛答辩呈现建议（可直接用）

### 10.1 5分钟讲解结构
1. 第1分钟：痛点与目标（为什么必须用 AI）。
2. 第2分钟：技术路线（6 节点闭环，不是黑盒回答）。
3. 第3分钟：现场演示（提问 -> 节点流 -> 结果 -> 导出）。
4. 第4分钟：效果数据（成功率、时延、救场率、效率提升）。
5. 第5分钟：价值与推广（可复制到更多院校与管理条线）。

### 10.2 评委高频问题应答口径
1. 你们的创新是什么？  
创新在“可验证执行 + 自修复 + 可观测”，不是简单接大模型聊天。

2. 为什么是 AI 应用而不是普通系统？  
核心决策流程由 AI 驱动，且能处理自然语言到结构化分析的自动转换。

3. 怎么证明可落地？  
系统已上线，具备真实用户流程、日志审计与部署体系。

---

## 11. 对照项目实现的关键事实（用于材料一致性）

1. AI工作流实现：`app/services/chat_graph.py`
2. 流式交互实现：`app/services/chat_stream_service.py`、`app/routers/chat.py`
3. 工作流结构说明：`WORKFLOW_NODE_IO.md`
4. 平台总览：`README.md`
5. 部署配置：`docker-compose.yml`、`deploy/nginx/default.conf`

